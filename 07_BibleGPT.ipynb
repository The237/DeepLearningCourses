{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3Ms3GXMR1sk4Q98rtzTb6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The237/DeepLearningCourses/blob/main/07_BibleGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLyaC4f6_N0M",
        "outputId": "1cb0efdc-bdef-4986-fb84-60cc8e6755b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")\n",
        "\n",
        "folder = \"/gdrive/MyDrive/deep_learning_courses/data/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(folder+\"fra-fraLSG.txt\") as f:\n",
        "  lines = f.readlines()"
      ],
      "metadata": {
        "id": "9LFaqR_IGndO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJI1B5qWG2xz",
        "outputId": "3d9df78f-d107-4dc3-fd17-81d8ec2c65fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41899"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines[30000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "A6Mwk5HKHDN8",
        "outputId": "382924e8-63a4-409f-c578-9bdb173e197f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sachant qu’un homme de cette espèce est perverti, et qu’il pèche, en se condamnant lui-même.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objectif : Prédire le prochain mot"
      ],
      "metadata": {
        "id": "lXo1atptHUTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**self supervised learning** : c'est à dire X et y sont dans la donnée de type texte."
      ],
      "metadata": {
        "id": "iWSICTAfHlxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nettoyage du corpus"
      ],
      "metadata": {
        "id": "qgGkLB8HKRKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_texts = 5000"
      ],
      "metadata": {
        "id": "eFOPCBLsaLM3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "for line in lines:\n",
        "  line = line.split(\"\\n\")[0]\n",
        "  line = line.lower()\n",
        "  if line:\n",
        "    corpus.append(line)"
      ],
      "metadata": {
        "id": "MTptE1YKHFo-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-45aSvVLZdI",
        "outputId": "cf0b169b-d8b2-4110-e038-cabe0636e7aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31055"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = corpus[:nb_texts]"
      ],
      "metadata": {
        "id": "5wilqgq1LEeg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisation"
      ],
      "metadata": {
        "id": "v7JPs40NLlbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "6sVjbJPzLi8X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(corpus)"
      ],
      "metadata": {
        "id": "KRrSqjE_MCxF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(corpus)"
      ],
      "metadata": {
        "id": "MWuxMuzpNpky"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1ge6FsyN1Y1",
        "outputId": "dc24f2dd-9593-415d-aaad-28aefce1dbb3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31, 2014, 38, 1265, 5, 750, 1, 4, 82]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4-LPs8ZMMY5",
        "outputId": "8de6a3f8-180b-4799-8077-f4a122f4c706"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7377"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for seq in sequences:\n",
        "  for i in range(1,len(seq)):\n",
        "    data_line = seq[:i+1]\n",
        "    input_sequences.append(data_line)"
      ],
      "metadata": {
        "id": "1eFj_U-pMPH8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTzaxMSvOCDQ",
        "outputId": "6c3bd3c3-4467-4c36-bdd6-a13661956abb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112024"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ],
      "metadata": {
        "id": "F-rGEPBzPTGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "eY0qSsrkOC3r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = max([len(x) for x in input_sequences])\n",
        "maxlen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJoMVqI6QMUx",
        "outputId": "6edb56b5-12b3-4491-a54e-59450261759f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = pad_sequences(input_sequences, padding=\"pre\", maxlen=maxlen)"
      ],
      "metadata": {
        "id": "cL-3MPuSOx9f"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create X_train and y_train"
      ],
      "metadata": {
        "id": "rUKIxU2QRGfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# on prend toutes les lignes et tout ce\n",
        "X_train = input_sequences[:, :-1]\n",
        "y_train = input_sequences[:, -1]"
      ],
      "metadata": {
        "id": "ILDvuVFXQ-N_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frC1iJ8WQ_RU",
        "outputId": "555f2565-861f-42df-909a-15034f6c5fc5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((112024, 65), (112024,))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train)"
      ],
      "metadata": {
        "id": "sB0Fo2WpRg0R"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfceAvRIVyNQ",
        "outputId": "1bfa4a72-a364-4a60-f672-f42eb200fa85"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7378"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "rbPfhZQ7V9FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CVno-WJXVzVd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 12\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        # vocab_size pour la taille du vocabulaire\n",
        "        Embedding(y_train.shape[1], embedding_dim),\n",
        "        Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "        tf.keras.layers.Dense(y_train.shape[1], activation =\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "K_vEMvEOWHii"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj-rKlFXYCKy",
        "outputId": "f3630204-f94d-4bf7-abde-351ce948c29b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 12)          88536     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 128)               39424     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7378)              951762    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1079722 (4.12 MB)\n",
            "Trainable params: 1079722 (4.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = model.fit(X_train, y_train, epochs = 20, batch_size = 1024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFzv2iIxYD-T",
        "outputId": "fa00c983-0fff-4cc5-f44d-a487a040f544"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "110/110 [==============================] - 27s 215ms/step - loss: 7.0096 - accuracy: 0.0438\n",
            "Epoch 2/20\n",
            "110/110 [==============================] - 13s 120ms/step - loss: 6.4407 - accuracy: 0.0465\n",
            "Epoch 3/20\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 6.3267 - accuracy: 0.0466\n",
            "Epoch 4/20\n",
            "110/110 [==============================] - 9s 77ms/step - loss: 6.1922 - accuracy: 0.0535\n",
            "Epoch 5/20\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 6.0893 - accuracy: 0.0620\n",
            "Epoch 6/20\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 6.0014 - accuracy: 0.0672\n",
            "Epoch 7/20\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 5.9268 - accuracy: 0.0730\n",
            "Epoch 8/20\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 5.8687 - accuracy: 0.0751\n",
            "Epoch 9/20\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 5.8245 - accuracy: 0.0769\n",
            "Epoch 10/20\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 5.7883 - accuracy: 0.0790\n",
            "Epoch 11/20\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 5.7530 - accuracy: 0.0808\n",
            "Epoch 12/20\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 5.7188 - accuracy: 0.0824\n",
            "Epoch 13/20\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 5.6793 - accuracy: 0.0847\n",
            "Epoch 14/20\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 5.6363 - accuracy: 0.0876\n",
            "Epoch 15/20\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 5.5889 - accuracy: 0.0922\n",
            "Epoch 16/20\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 5.5391 - accuracy: 0.0978\n",
            "Epoch 17/20\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 5.4907 - accuracy: 0.1016\n",
            "Epoch 18/20\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 5.4452 - accuracy: 0.1071\n",
            "Epoch 19/20\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 5.4008 - accuracy: 0.1100\n",
            "Epoch 20/20\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 5.3584 - accuracy: 0.1149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Générer du texte"
      ],
      "metadata": {
        "id": "HZxHt6NycC27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"la tente d'assignation\"\n",
        "prompt = prompt.lower()"
      ],
      "metadata": {
        "id": "SKn3Jt7EcEXn"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "meObXI2Ilp4A",
        "outputId": "1bece91b-140e-4e3c-f4b0-42c728396a6b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jesus est'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenisation\n",
        "prompt_seq = tokenizer.texts_to_sequences([prompt])\n",
        "# padding\n",
        "prompt_x = pad_sequences([prompt_seq[0]], maxlen=maxlen-1, padding=\"pre\")"
      ],
      "metadata": {
        "id": "0ceHyN2gcPic"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(prompt_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmos7zQmdRDK",
        "outputId": "1a2c9408-f0cf-4a4b-9e25-399f95e32c07"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCGNeEr0duAk",
        "outputId": "9dc22649-9b45-4b09-c4ba-b9fd01747906"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.index_word.get(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dKh6cDh6dRu6",
        "outputId": "6988dd27-8d12-4558-8272-cc3a090a5e2f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'de'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_predict = 10\n",
        "\n",
        "for _ in range(n_predict):\n",
        "  # tokenisation\n",
        "  prompt_seq = tokenizer.texts_to_sequences([prompt])\n",
        "\n",
        "  # padding\n",
        "  prompt_x = pad_sequences([prompt_seq[0]], maxlen=maxlen-1, padding=\"pre\")\n",
        "\n",
        "  # prediction\n",
        "  pred = model.predict(prompt_x)\n",
        "\n",
        "  index = np.argmax(pred)\n",
        "  mot_predit = tokenizer.index_word.get(index)\n",
        "  print(prompt+\" \"+mot_predit)\n",
        "\n",
        "  prompt = prompt+\" \"+mot_predit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFfZxlxyd9gq",
        "outputId": "fc4f1f59-4cab-455a-acff-0e13b3895875"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "la tente d'assignation d’assignation\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "la tente d'assignation d’assignation de\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "la tente d'assignation d’assignation de la\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "la tente d'assignation d’assignation de la fils\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "la tente d'assignation d’assignation de la fils de\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "la tente d'assignation d’assignation de la fils de la\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "la tente d'assignation d’assignation de la fils de la fils\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "la tente d'assignation d’assignation de la fils de la fils de\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "la tente d'assignation d’assignation de la fils de la fils de la\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "la tente d'assignation d’assignation de la fils de la fils de la fils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "htGIe7EqlBhQ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFzPftcYlCy7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}